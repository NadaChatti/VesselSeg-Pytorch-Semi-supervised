protocolVersion: 2
name: unet
type: job
prerequisites:
  - name: image
    type: dockerimage
    uri: >-
      master.garching.cluster.campar.in.tum.de:10443/camp/ubuntu_20.04-python_3.8-cuda_11.3-pytorch_1.11-gpu
#     auth:
#       username: <username>
#       password: <% $secrets.docker_password_0 %>
#       registryuri: 'master.garching.cluster.campar.in.tum.de:10443'
# secrets:
#   docker_password_0: <harbor_cli_secret>
taskRoles:
  train:
    instances: 1
    dockerImage: image
    resourcePerInstance:
      cpu: 4
      memoryMB: 30000
      gpu: 1
    nodeSelectionPerInstance:
      - key: nvidia.com/gpu.memory
        operator: Gt
        values:
          - '0'
      - key: nvidia.com/gpu.compute.major
        operator: Gt
        values:
          - '0'
    commands:
      - echo "Start"
      - export PAI_AUTO_UPLOAD_DIR=/mnt/workfiles/VesselSeg-Pytorch-Semi-supervised
      # - export PAI_AUTO_UPLOAD_DIR=/mnt/workfiles/${PAI_JOB_NAME}
      - cd ${PAI_AUTO_UPLOAD_DIR}
      - python3 -m pip install --upgrade pip
      - pip install tqdm
      - pip install tensorboardx
      - pip install opencv-python
      - pip install matplotlib
      - pip install scikit-image
      - pip install medpy
      - pip install h5py
      - export HDF5_USE_FILE_LOCKING='FALSE'
      - python3 code/train_dca1_unet.py --no-validate --exp unet
      - python3 code/train_dca1_unet.py --dataset DRIVE --no-validate --labelnum 8 --exp unet

extras:
  com.microsoft.pai.runtimeplugin:
    - plugin: ssh
      parameters:
        jobssh: true
    - plugin: tensorboard
      parameters:
        logdir:
          path: /mnt/workfiles/VesselSeg-Pytorch-Semi-supervised/model/DCA1/
    - plugin: teamwise_storage
      parameters:
        storageConfigNames:
          - nfs-datasets
          - nfs-projects
          - nfs-workfiles
  jobStatusChangeNotification:
    running: false
    succeeded: false
    stopped: false
    failed: false
    retried: false